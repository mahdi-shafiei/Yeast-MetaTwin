{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import rdChemReactions\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from IPython.display import SVG, display\n",
    "from rdkit.Chem.Fingerprints import FingerprintMols\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import MACCSkeys\n",
    "import pandas as pd\n",
    "import os\n",
    "import itertools\n",
    "import pickle\n",
    "import sys\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from tqdm import tqdm \n",
    "import cobra\n",
    "from itertools import chain, combinations\n",
    "import sys\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "tqdm.pandas()\n",
    "# sys.path.append('../Code/')\n",
    "sys.path.append('../')\n",
    "\n",
    "from common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input\n",
    "num = 50\n",
    "cut_off = 0.3\n",
    "cut_off_retrosynthesis_path = f'../../../Data_retrosynthesis/not_lipid_filter20percent/top{num}_{cut_off}_add_no_ec_re/'\n",
    "cut_off_path = f'../../../Results/not_lipid_filter20percent/top{num}_{cut_off}_add_no_ec_re/'\n",
    "not_lipid_rxndb_path = cut_off_retrosynthesis_path + 'RXNdb_top50_0.3/'\n",
    "not_lipid_YMDB_fail_met_smile_uptake_file = cut_off_path + f'YMDB_fail_met_smile_top{num}_{cut_off}.pickle'\n",
    "# total_met_inchikey0_file = '../../../Results/analysis/total_met_inchikey0.pickle'\n",
    "total_met_inchikey0_file = '../../../Results/analysis/total_met_inchikey0_filter.pickle'\n",
    "YMDB_fail_met_smile_file = cut_off_path + f'YMDB_fail_met_smile_top{num}_{cut_off}.pickle'\n",
    "uptake_met_path = '../../../Data/ymdb/ymdb_uptake.csv'\n",
    "rxndb_path = cut_off_retrosynthesis_path + f'RXNdb_top{num}_{cut_off}/'\n",
    "not_lipid_target_smiles_filter20percent_else_path = '../../../Results/not_lipid_filter20percent/target_smiles_not_lipid_filter20percent_else.pickle'\n",
    "\n",
    "#output\n",
    "not_lipid_rxndb_inteme_drop_duplicate_path = cut_off_path + f'RXNdb_all_top50_0.3_all.csv'\n",
    "not_lipid_fail_target_rxndb_path = cut_off_retrosynthesis_path + 'RXNdb_fail_target/'\n",
    "not_lipid_rxndb_inteme_only_one_new_path = cut_off_path + 'RXNdb_inteme_only_one_new_top50_drop_unvalid.csv'\n",
    "not_lipid_rxndb_inteme_only_one_new_target_path = cut_off_path + 'RXNdb_inteme_only_one_new_target_top50.csv'\n",
    "sink0_path = cut_off_path + 'sink0_new_met_only_new_one_top50.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(not_lipid_fail_target_rxndb_path):\n",
    "    os.makedirs(not_lipid_fail_target_rxndb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file_mer(file,rxndb_path,inchikey0,rxndb_drop_path):\n",
    "    with open(rxndb_path + file, 'r') as f:\n",
    "        rxndb = json.load(f)    \n",
    "    remove = []\n",
    "    for k,v in rxndb.items():\n",
    "        \n",
    "        productsmile = v['productsmile'].split('.')\n",
    "        if any([smiles2inchikey0(p) in inchikey0  for p in productsmile]):\n",
    "            pass\n",
    "        else:\n",
    "            remove.append(k)\n",
    "    for k in remove:\n",
    "        rxndb.pop(k)\n",
    "    with open(rxndb_drop_path + file, 'w') as f:\n",
    "        json.dump(rxndb, f,indent=4)\n",
    "\n",
    "def drop_rxndb_mer(rxndb_path, rxndb_drop_path, inchikey0,num_processes=60):\n",
    "    files = os.listdir(rxndb_path)\n",
    "    process_file_partial = partial(process_file_mer,rxndb_path=rxndb_path,inchikey0=inchikey0,rxndb_drop_path=rxndb_drop_path)\n",
    "    with mp.Pool(num_processes) as p:\n",
    "        list(tqdm(p.imap_unordered(process_file_partial, files), total=len(files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not_lipid_YMDB_fail_met_smile = pickle.load(open(not_lipid_YMDB_fail_met_smile_uptake_file, 'rb'))\n",
    "not_lipid_YMDB_fail_met_smile = pickle.load(open(not_lipid_target_smiles_filter20percent_else_path, 'rb'))\n",
    "not_lipid_YMDB_fail_met_inchikey0 = [smiles2inchikey0(smile) for smile in not_lipid_YMDB_fail_met_smile ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29161/29161 [04:38<00:00, 104.61it/s]\n"
     ]
    }
   ],
   "source": [
    "drop_rxndb_mer(not_lipid_rxndb_path, not_lipid_fail_target_rxndb_path, not_lipid_YMDB_fail_met_inchikey0,num_processes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file_drop_duplicate(file,rxndb_path):\n",
    "    try:\n",
    "        with open(rxndb_path + file, 'r') as f:\n",
    "            rxndb = json.load(f)    \n",
    "    \n",
    "        if len(rxndb) != 0:\n",
    "            rxndb_df = pd.DataFrame(rxndb).transpose()\n",
    "            \n",
    "            rxndb_df['reactant_inchikey0'] = rxndb_df['reactant_smile'].apply(lambda x: '.'.join(sorted([smiles2inchikey0(i) for i in (x.split('.'))])))\n",
    "            rxndb_df['product_inchikey0'] = rxndb_df['productsmile'].apply(lambda x: '.'.join(sorted([smiles2inchikey0(i) for i in (x.split('.'))])))\n",
    "            # rxndb_df['product_inchikey0'] = rxndb_df['product_inchikey0'].apply(lambda x: '.'.join(sorted(x.split('.'))))\n",
    "            # rxndb_df['reactant_inchikey0'] = rxndb_df['reactant_inchikey0'].apply(lambda x: '.'.join(sorted(x.split('.'))))\n",
    "            rxndb = rxndb_df.to_dict(orient='index')\n",
    "            with open(rxndb_path + file, 'w') as f:\n",
    "                json.dump(rxndb, f,indent=4)\n",
    "    except:\n",
    "        print(file)\n",
    "        pass\n",
    "\n",
    "def process_file_drop_duplicate_parallel(rxndb_path,num_processes=50):\n",
    "    files = os.listdir(rxndb_path)\n",
    "#     files = ['RXNdb_14838.json','RXNdb_7284.json','RXNdb_10683.json','RXNdb_10627.json',\n",
    "# 'RXNdb_17365.json','RXNdb_13669.json','RXNdb_14857.json','RXNdb_15735.json','RXNdb_5346.json','RXNdb_7276.json']\n",
    "    process_file_partial = partial(process_file_drop_duplicate,rxndb_path=rxndb_path)\n",
    "    with mp.Pool(num_processes) as p:\n",
    "        list(tqdm(p.imap_unordered(process_file_partial, files), total=len(files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicate_rxndb(not_lipid_rxndb_inteme_drop_duplicate_path,rxndb_path):\n",
    "    files = os.listdir(rxndb_path) \n",
    "    with open(rxndb_path + files[0], 'r') as f:\n",
    "        rxndb_total = json.load(f)\n",
    "        rxndb_total_df = pd.DataFrame(rxndb_total).transpose()\n",
    "    for file in tqdm(files[1:],total=len(files[1:])):\n",
    "        with open(rxndb_path + file, 'r') as f:\n",
    "            rxndb = json.load(f) \n",
    "\n",
    "        rxndb_df = pd.DataFrame(rxndb).transpose()\n",
    "        rxndb_total_df = pd.concat([rxndb_total_df,rxndb_df],axis=0)\n",
    "    rxndb_total_df = rxndb_total_df.drop_duplicates(subset=['reactant_inchikey0', 'product_inchikey0'], keep='first').reset_index(drop=True)\n",
    "    rxndb_total_df.to_csv(not_lipid_rxndb_inteme_drop_duplicate_path )\n",
    "    print(rxndb_total_df.shape)\n",
    "\n",
    "def drop_duplicate_rxndb(not_lipid_rxndb_inteme_drop_duplicate_path, rxndb_path):\n",
    "    files = os.listdir(rxndb_path) \n",
    "    all_data = []  # 用列表临时存储每个文件的数据\n",
    "    for file in tqdm(files, total=len(files), desc=\"Processing files\"):\n",
    "        with open(os.path.join(rxndb_path, file), 'r') as f:  # 使用 os.path.join 更稳健\n",
    "            rxndb = json.load(f)\n",
    "        rxndb_df = pd.DataFrame(rxndb).transpose()\n",
    "        all_data.append(rxndb_df)  # 将每个 DataFrame 添加到列表中\n",
    "    # 一次性合并所有 DataFrame\n",
    "    rxndb_total_df = pd.concat(all_data, axis=0)\n",
    "    # 去重\n",
    "    rxndb_total_df = rxndb_total_df.drop_duplicates(subset=['reactant_inchikey0', 'product_inchikey0'], keep='first').reset_index(drop=True)\n",
    "    # 保存到 CSV 文件\n",
    "    rxndb_total_df.to_csv(not_lipid_rxndb_inteme_drop_duplicate_path, index=False)  # index=False 避免多余索引\n",
    "\n",
    "    # 打印最终 DataFrame 的行列数\n",
    "    print(f\"Final DataFrame shape: {rxndb_total_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1308/29161 [00:13<11:19, 41.01it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29161/29161 [12:53<00:00, 37.72it/s] \n"
     ]
    }
   ],
   "source": [
    "process_file_drop_duplicate_parallel(not_lipid_fail_target_rxndb_path,num_processes=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|          | 0/29161 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 29161/29161 [06:39<00:00, 72.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame shape: (978830, 11)\n"
     ]
    }
   ],
   "source": [
    "drop_duplicate_rxndb(not_lipid_rxndb_inteme_drop_duplicate_path,not_lipid_fail_target_rxndb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1130, 13)\n",
      "(1130, 13)\n",
      "(1130, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>EC number</th>\n",
       "      <th>rule</th>\n",
       "      <th>templateID</th>\n",
       "      <th>templateSubstrate</th>\n",
       "      <th>rxn_smiles_basic</th>\n",
       "      <th>rxn_smiles_final</th>\n",
       "      <th>reactant_smile</th>\n",
       "      <th>productsmile</th>\n",
       "      <th>similarity</th>\n",
       "      <th>reactant_inchikey0</th>\n",
       "      <th>product_inchikey0</th>\n",
       "      <th>new_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>3.1.3.25</td>\n",
       "      <td>[C:1]-[OH;D1;+0:2].[O;-;D1;H0:4]-[P;H0;D4;+0:3...</td>\n",
       "      <td>MNXR151315_reverse</td>\n",
       "      <td>['O[C@H]1[C@H](O)[C@@H](O)[C@H](O)[C@@H](O)[C@...</td>\n",
       "      <td>O.O=P([O-])([O-])OC1C(O)C(O)C(OP(=O)([O-])[O-]...</td>\n",
       "      <td>O.O=P([O-])([O-])OC1C(O)C(O)C(OP(=O)([O-])[O-]...</td>\n",
       "      <td>O.O=P([O-])([O-])OC1C(O)C(O)C(OP(=O)([O-])[O-]...</td>\n",
       "      <td>O=P([O-])([O-])OC1C(O)C(O)C(O)C(O)C1O.O=P([O-]...</td>\n",
       "      <td>[0.6296296296, 1]</td>\n",
       "      <td>[PELZSPZCXGTUMR, XLYOFNOQVPJJNP]</td>\n",
       "      <td>[INAPMGSXUVUWAF, NBIIXXVUZAFLBC]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>3.1.3.25</td>\n",
       "      <td>[C:1]-[OH;D1;+0:2].[O;-;D1;H0:4]-[P;H0;D4;+0:3...</td>\n",
       "      <td>MNXR151315_reverse</td>\n",
       "      <td>['O[C@H]1[C@H](O)[C@@H](O)[C@H](O)[C@@H](O)[C@...</td>\n",
       "      <td>O.O=P([O-])([O-])OC1C(O)C(O)C(O)C(O)C1OP(=O)([...</td>\n",
       "      <td>O.O=P([O-])([O-])OC1C(O)C(O)C(O)C(O)C1OP(=O)([...</td>\n",
       "      <td>O.O=P([O-])([O-])OC1C(O)C(O)C(O)C(O)C1OP(=O)([...</td>\n",
       "      <td>O=P([O-])([O-])OC1C(O)C(O)C(O)C(O)C1O.O=P([O-]...</td>\n",
       "      <td>[0.6296296296, 1]</td>\n",
       "      <td>[MCKAJXMRULSUKI, XLYOFNOQVPJJNP]</td>\n",
       "      <td>[INAPMGSXUVUWAF, NBIIXXVUZAFLBC]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>3.1.3.25</td>\n",
       "      <td>[C:1]-[OH;D1;+0:2].[O;-;D1;H0:4]-[P;H0;D4;+0:3...</td>\n",
       "      <td>MNXR151315_reverse</td>\n",
       "      <td>['O[C@H]1[C@H](O)[C@@H](O)[C@H](O)[C@@H](O)[C@...</td>\n",
       "      <td>O.O=P([O-])([O-])OC1C(O)C(OP(=O)([O-])[O-])C(O...</td>\n",
       "      <td>O.O=P([O-])([O-])OC1C(O)C(OP(=O)([O-])[O-])C(O...</td>\n",
       "      <td>O.O=P([O-])([O-])OC1C(O)C(OP(=O)([O-])[O-])C(O...</td>\n",
       "      <td>O=P([O-])([O-])OC1C(O)C(O)C(OP(=O)([O-])[O-])C...</td>\n",
       "      <td>[0.6071428571, 1]</td>\n",
       "      <td>[XLYOFNOQVPJJNP, ZAWIXNGTTZTBKV]</td>\n",
       "      <td>[MMWCIQZXVOZEGG, NBIIXXVUZAFLBC]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>112</td>\n",
       "      <td>3.1.3.25</td>\n",
       "      <td>[C:1]-[OH;D1;+0:2].[O;-;D1;H0:4]-[P;H0;D4;+0:3...</td>\n",
       "      <td>MNXR151315_reverse</td>\n",
       "      <td>['O[C@H]1[C@H](O)[C@@H](O)[C@H](O)[C@@H](O)[C@...</td>\n",
       "      <td>O.O=P([O-])([O-])OCC1OC(OC2(CO)OC(CO)C(O)C2O)C...</td>\n",
       "      <td>O.O=P([O-])([O-])OCC1OC(OC2(CO)OC(CO)C(O)C2O)C...</td>\n",
       "      <td>O.O=P([O-])([O-])OCC1OC(OC2(CO)OC(CO)C(O)C2O)C...</td>\n",
       "      <td>OCC1OC(OC2(CO)OC(CO)C(O)C2O)C(O)C(O)C1O.O=P([O...</td>\n",
       "      <td>[0.4857142857, 1]</td>\n",
       "      <td>[WQQSIXKPRAUZJL, XLYOFNOQVPJJNP]</td>\n",
       "      <td>[CZMRCDWAGMRECN, NBIIXXVUZAFLBC]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>125</td>\n",
       "      <td>3.1.3.25</td>\n",
       "      <td>[C:1]-[OH;D1;+0:2].[O;-;D1;H0:4]-[P;H0;D4;+0:3...</td>\n",
       "      <td>MNXR151315_reverse</td>\n",
       "      <td>['O[C@H]1[C@H](O)[C@@H](O)[C@H](O)[C@@H](O)[C@...</td>\n",
       "      <td>O.O=P([O-])([O-])OC1(CO)OC(CO)C(O)C1O&gt;&gt;OCC1OC(...</td>\n",
       "      <td>O.O=P([O-])([O-])OC1(CO)OC(CO)C(O)C1O&gt;&gt;OCC1OC(...</td>\n",
       "      <td>O.O=P([O-])([O-])OC1(CO)OC(CO)C(O)C1O</td>\n",
       "      <td>OCC1OC(O)(CO)C(O)C1O.O=P([O-])([O-])O</td>\n",
       "      <td>[0.48484848480000003, 1]</td>\n",
       "      <td>[PMTUDJVZIGZBIX, XLYOFNOQVPJJNP]</td>\n",
       "      <td>[NBIIXXVUZAFLBC, RFSUNEUAIZKAJO]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0 EC number                                               rule  \\\n",
       "18           18  3.1.3.25  [C:1]-[OH;D1;+0:2].[O;-;D1;H0:4]-[P;H0;D4;+0:3...   \n",
       "19           19  3.1.3.25  [C:1]-[OH;D1;+0:2].[O;-;D1;H0:4]-[P;H0;D4;+0:3...   \n",
       "28           28  3.1.3.25  [C:1]-[OH;D1;+0:2].[O;-;D1;H0:4]-[P;H0;D4;+0:3...   \n",
       "112         112  3.1.3.25  [C:1]-[OH;D1;+0:2].[O;-;D1;H0:4]-[P;H0;D4;+0:3...   \n",
       "125         125  3.1.3.25  [C:1]-[OH;D1;+0:2].[O;-;D1;H0:4]-[P;H0;D4;+0:3...   \n",
       "\n",
       "             templateID                                  templateSubstrate  \\\n",
       "18   MNXR151315_reverse  ['O[C@H]1[C@H](O)[C@@H](O)[C@H](O)[C@@H](O)[C@...   \n",
       "19   MNXR151315_reverse  ['O[C@H]1[C@H](O)[C@@H](O)[C@H](O)[C@@H](O)[C@...   \n",
       "28   MNXR151315_reverse  ['O[C@H]1[C@H](O)[C@@H](O)[C@H](O)[C@@H](O)[C@...   \n",
       "112  MNXR151315_reverse  ['O[C@H]1[C@H](O)[C@@H](O)[C@H](O)[C@@H](O)[C@...   \n",
       "125  MNXR151315_reverse  ['O[C@H]1[C@H](O)[C@@H](O)[C@H](O)[C@@H](O)[C@...   \n",
       "\n",
       "                                      rxn_smiles_basic  \\\n",
       "18   O.O=P([O-])([O-])OC1C(O)C(O)C(OP(=O)([O-])[O-]...   \n",
       "19   O.O=P([O-])([O-])OC1C(O)C(O)C(O)C(O)C1OP(=O)([...   \n",
       "28   O.O=P([O-])([O-])OC1C(O)C(OP(=O)([O-])[O-])C(O...   \n",
       "112  O.O=P([O-])([O-])OCC1OC(OC2(CO)OC(CO)C(O)C2O)C...   \n",
       "125  O.O=P([O-])([O-])OC1(CO)OC(CO)C(O)C1O>>OCC1OC(...   \n",
       "\n",
       "                                      rxn_smiles_final  \\\n",
       "18   O.O=P([O-])([O-])OC1C(O)C(O)C(OP(=O)([O-])[O-]...   \n",
       "19   O.O=P([O-])([O-])OC1C(O)C(O)C(O)C(O)C1OP(=O)([...   \n",
       "28   O.O=P([O-])([O-])OC1C(O)C(OP(=O)([O-])[O-])C(O...   \n",
       "112  O.O=P([O-])([O-])OCC1OC(OC2(CO)OC(CO)C(O)C2O)C...   \n",
       "125  O.O=P([O-])([O-])OC1(CO)OC(CO)C(O)C1O>>OCC1OC(...   \n",
       "\n",
       "                                        reactant_smile  \\\n",
       "18   O.O=P([O-])([O-])OC1C(O)C(O)C(OP(=O)([O-])[O-]...   \n",
       "19   O.O=P([O-])([O-])OC1C(O)C(O)C(O)C(O)C1OP(=O)([...   \n",
       "28   O.O=P([O-])([O-])OC1C(O)C(OP(=O)([O-])[O-])C(O...   \n",
       "112  O.O=P([O-])([O-])OCC1OC(OC2(CO)OC(CO)C(O)C2O)C...   \n",
       "125              O.O=P([O-])([O-])OC1(CO)OC(CO)C(O)C1O   \n",
       "\n",
       "                                          productsmile  \\\n",
       "18   O=P([O-])([O-])OC1C(O)C(O)C(O)C(O)C1O.O=P([O-]...   \n",
       "19   O=P([O-])([O-])OC1C(O)C(O)C(O)C(O)C1O.O=P([O-]...   \n",
       "28   O=P([O-])([O-])OC1C(O)C(O)C(OP(=O)([O-])[O-])C...   \n",
       "112  OCC1OC(OC2(CO)OC(CO)C(O)C2O)C(O)C(O)C1O.O=P([O...   \n",
       "125              OCC1OC(O)(CO)C(O)C1O.O=P([O-])([O-])O   \n",
       "\n",
       "                   similarity                reactant_inchikey0  \\\n",
       "18          [0.6296296296, 1]  [PELZSPZCXGTUMR, XLYOFNOQVPJJNP]   \n",
       "19          [0.6296296296, 1]  [MCKAJXMRULSUKI, XLYOFNOQVPJJNP]   \n",
       "28          [0.6071428571, 1]  [XLYOFNOQVPJJNP, ZAWIXNGTTZTBKV]   \n",
       "112         [0.4857142857, 1]  [WQQSIXKPRAUZJL, XLYOFNOQVPJJNP]   \n",
       "125  [0.48484848480000003, 1]  [PMTUDJVZIGZBIX, XLYOFNOQVPJJNP]   \n",
       "\n",
       "                    product_inchikey0  new_num  \n",
       "18   [INAPMGSXUVUWAF, NBIIXXVUZAFLBC]        1  \n",
       "19   [INAPMGSXUVUWAF, NBIIXXVUZAFLBC]        1  \n",
       "28   [MMWCIQZXVOZEGG, NBIIXXVUZAFLBC]        1  \n",
       "112  [CZMRCDWAGMRECN, NBIIXXVUZAFLBC]        1  \n",
       "125  [NBIIXXVUZAFLBC, RFSUNEUAIZKAJO]        1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total_inchikey0 = load_pickle(total_met_inchikey0_file)\n",
    "# not_lipid_target_smiles_filter20percent_else_path = '../../../Results/not_lipid_filter20percent/target_smiles_not_lipid_filter20percent_else.pickle'\n",
    "# not_lipid_target_smiles_filter20percent_else = load_pickle(not_lipid_target_smiles_filter20percent_else_path)\n",
    "# filter_inchi = [smiles2inchikey0(x) for x in not_lipid_target_smiles_filter20percent_else]\n",
    "# for x in filter_inchi:\n",
    "#     if x in total_inchikey0:\n",
    "#         print(x)\n",
    "\n",
    "# rxndb_total_df = pd.read_csv(not_lipid_rxndb_inteme_drop_duplicate_path)\n",
    "# print(rxndb_total_df.shape)\n",
    "# rxndb_total_df['new_num'] = None\n",
    "# rxndb_total_df['reactant_inchikey0'] = rxndb_total_df['reactant_inchikey0'].apply(lambda x: x.split('.'))\n",
    "# rxndb_total_df['product_inchikey0'] = rxndb_total_df['product_inchikey0'].apply(lambda x: x.split('.'))\n",
    "# rxndb_total_df['new_num'] = rxndb_total_df['product_inchikey0'].apply(lambda x: sum([1 for i in x if i not in total_inchikey0]))\n",
    "# rxndb_total_df = rxndb_total_df[rxndb_total_df['new_num'] == 0]\n",
    "# print(rxndb_total_df.shape)\n",
    "# rxndb_total_df['new_num'] = rxndb_total_df['reactant_inchikey0'].apply(lambda x: sum([1 for i in x if i in filter_inchi ]))\n",
    "# rxndb_total_df = rxndb_total_df[rxndb_total_df['new_num'] > 0]\n",
    "# print(rxndb_total_df.shape)\n",
    "# rxndb_total_df['new_num'] = rxndb_total_df['reactant_inchikey0'].apply(lambda x: sum([1 for i in x if i not in total_inchikey0 ]))\n",
    "# rxndb_total_df = rxndb_total_df[rxndb_total_df['new_num'] == 1]\n",
    "# print(rxndb_total_df.shape)\n",
    "# rxndb_total_df['product_inchikey0'] = rxndb_total_df['product_inchikey0'].apply(lambda x: ('.').join(x))\n",
    "# rxndb_total_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_only_one_new(not_lipid_rxndb_inteme_drop_duplicate_path,total_inchikey0,not_lipid_rxndb_inteme_only_one_new_path):\n",
    "    rxndb_total_df = pd.read_csv(not_lipid_rxndb_inteme_drop_duplicate_path)\n",
    "    rxndb_total_df['new_num'] = None\n",
    "    rxndb_total_df['reactant_inchikey0'] = rxndb_total_df['reactant_inchikey0'].apply(lambda x: x.split('.'))\n",
    "    rxndb_total_df['new_num'] = rxndb_total_df['reactant_inchikey0'].apply(lambda x: sum([1 for i in x if i not in total_inchikey0 ]))\n",
    "    rxndb_total_df = rxndb_total_df[rxndb_total_df['new_num'] == 1]\n",
    "    rxndb_total_df.to_csv(not_lipid_rxndb_inteme_only_one_new_path)\n",
    "\n",
    "def choose_only_one_new(not_lipid_rxndb_inteme_drop_duplicate_path,not_lipid_target_smiles_filter20percent_else_path,total_inchikey0,not_lipid_rxndb_inteme_only_one_new_path):\n",
    "    rxndb_total_df = pd.read_csv(not_lipid_rxndb_inteme_drop_duplicate_path)\n",
    "    not_lipid_target_smiles_filter20percent_else = load_pickle(not_lipid_target_smiles_filter20percent_else_path)\n",
    "    filter_inchi = [smiles2inchikey0(x) for x in not_lipid_target_smiles_filter20percent_else]\n",
    "    rxndb_total_df['reactant_inchikey0'] = rxndb_total_df['reactant_inchikey0'].apply(lambda x: x.split('.'))\n",
    "    rxndb_total_df['product_inchikey0'] = rxndb_total_df['product_inchikey0'].apply(lambda x: x.split('.'))\n",
    "    print(rxndb_total_df.shape)\n",
    "    tqdm.pandas()\n",
    "    rxndb_total_df['new_num'] = rxndb_total_df['product_inchikey0'].progress_apply(lambda x: sum([1 for i in x if i not in total_inchikey0]))\n",
    "    rxndb_total_df = rxndb_total_df[rxndb_total_df['new_num'] == 0]\n",
    "    print(rxndb_total_df.shape)\n",
    "    rxndb_total_df['new_num'] = rxndb_total_df['reactant_inchikey0'].progress_apply(lambda x: sum([1 for i in x if i in filter_inchi ]))\n",
    "    rxndb_total_df = rxndb_total_df[rxndb_total_df['new_num'] > 0]\n",
    "    print(rxndb_total_df.shape)\n",
    "    rxndb_total_df['new_num'] = rxndb_total_df['reactant_inchikey0'].progress_apply(lambda x: sum([1 for i in x if i not in total_inchikey0 ]))\n",
    "    rxndb_total_df = rxndb_total_df[rxndb_total_df['new_num'] == 1]\n",
    "    print(rxndb_total_df.shape)\n",
    "    rxndb_total_df['product_inchikey0'] = rxndb_total_df['product_inchikey0'].apply(lambda x: ('.').join(x))\n",
    "\n",
    "    rxndb_total_df.to_csv(not_lipid_rxndb_inteme_only_one_new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(978830, 11)\n",
      "(978086, 12)\n",
      "(3131, 12)\n",
      "(492, 12)\n"
     ]
    }
   ],
   "source": [
    "total_inchikey0 = load_pickle(total_met_inchikey0_file)\n",
    "choose_only_one_new(not_lipid_rxndb_inteme_drop_duplicate_path,not_lipid_target_smiles_filter20percent_else_path,total_inchikey0,not_lipid_rxndb_inteme_only_one_new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df):\n",
    "    for index, row in df.iterrows():\n",
    "        reactant_smile = row['reactant_smile'].split('.')\n",
    "        for i in reactant_smile:\n",
    "            if not Chem.MolFromSmiles(i):\n",
    "                df.drop(index, inplace=True)\n",
    "                break\n",
    "    for index, row in df.iterrows():\n",
    "        productsmile = row['productsmile'].split('.')\n",
    "        for i in productsmile:\n",
    "            if not Chem.MolFromSmiles(i):\n",
    "                df.drop(index, inplace=True)\n",
    "                break\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(492, 13)\n"
     ]
    }
   ],
   "source": [
    "not_lipid_rxndb_inteme_only_one_new = pd.read_csv(not_lipid_rxndb_inteme_only_one_new_path)\n",
    "print(not_lipid_rxndb_inteme_only_one_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 1247.73it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(492, 13)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = np.array_split(not_lipid_rxndb_inteme_only_one_new, 50)\n",
    "with mp.Pool(50) as pool:\n",
    "    results = list(tqdm(pool.imap(filter_df, chunks), total=len(chunks)))\n",
    "rxndb_total_df = pd.concat(results)\n",
    "rxndb_total_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxndb_total_df.to_csv(not_lipid_rxndb_inteme_only_one_new_target_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(978830, 11)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_lipid_rxndb_inteme_drop_duplica = pd.read_csv(not_lipid_rxndb_inteme_drop_duplicate_path)\n",
    "not_lipid_rxndb_inteme_drop_duplica.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kcat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
